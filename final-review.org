#+AUTHOR: J. Alexander Branham
#+TITLE: Stats I review
#+EMAIL: branham@utexas.edu
#+DATE: Fall 2015
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{mathtools}

This document is intended as a review guide for a few topics we
covered in the second half of the semester in Statistics I,
Fall 2015. 
* MLE estimation
  Maximum likelihood estimation (MLE) is a way of getting an
  estimator. In particular, MLE asks "What's the value for this
  parameter that makes my data the most likely to have occurred?" In
  order to get this, all we need to do is to write out the likelihood
  function then find its maximum. Oftentimes, we'll take the log of
  the likelihood function before finding the maximum because taking
  the derivative of the log of the likelihood function is oftentimes
  easier. It will give you the same value, though. 
** Step 1: Find the likelihood function
   We can find the likelihood function $L(\theta)$ by simply multiplying
   together the probability of each $X_i$, if they're independent
   (which is what we generally assume). That's simple to do:
  
   \begin{equation}
   L(\theta) = \prod_{i=1}^n f(x_i | \theta)
   \end{equation}
*** Step 1b
    Mathematically, the product from the previous equation becomes
    difficult to work with for a variety of reasons. Therefore, we
    oftentimes take the log of the likelihood function which turns the
    product into summation. Note that for very simple examples, this
    isn't necessary. For more complicated examples, this makes your
    life easier. It is also how computers calculate MLE. 
   
    \begin{equation}
    \log (L(x|\theta)) = \mathcal{L}(x|\theta) = \sum_{i=1}^n f(x_i | \theta)
    \end{equation}

    Note that this step isn't absolutely necessary. It just makes the
    math easier (usually) and will always give the same values as if
    you didn't take the log. 
** Step 3: Find the maximum of the log-likelihood 
   Now that we have formally specified the likelihood of our data in
   terms of an unknown $\theta$, we can find the value for $\theta$ that
   maximizes the likelihood of our data. We could do this by hand,
   plugging in all of the possible values for $\theta$. But that would take
   a while and be a lot of work, so we can use /optimization/
   instead. This is the process of finding the maximum (or minimum) of
   a function. 

   Mechanically, this is pretty simple. We simply take the derivative
   of the (log) likelihood and set it equal to zero. To ensure we've
   found a maximum (instead of a minimum), we also need to check the
   second derivative to make sure it's negative. 
** Example
   Suppose that $X$ is a Bernoulli random variable and we observe 183
   0's and 78 1's. What is the MLE for $p$? 

*** Find likelihood function
    If we let $k$ represent the number of successes we have, then the
    likelihood function is then:
    
    \begin{equation}
    \begin{split}
    L(X|p) & = \prod_{i=1}^n Pr(X=x_i | p) \\
           & = p^k (1-p)^{n-k}
    \end{split}
    \end{equation}

    Which for our data is simply $L(X|p) = p^{78}(1-p)^{261-78}$

    
    At this point, if the likelihood function looks like it's going to
    be a beast to maximize, you can take the log of it to make the
    math easier. This one won't give us a problem, though. 

    We can look at the likelihood function to see where we think
    our estimate might be. We can see from Figure [[fig:likelihood]]
    that the maximum likelihood of our data occurs somewhere around $\theta
    = 0.26$. 

    #+BEGIN_SRC R :results output graphics :file figures/MLE_likelihood.png :width 400 :height 300 :exports both
      our_like<- function(p){
        p ^ 78 * (1 - p) ^ (261 - 78)
      }

      ggplot2::qplot(c(0,1), stat = "function",
                     fun = our_like,
                     geom = "line")

    #+END_SRC

    #+NAME: fig:likelihood
    #+CAPTION: Graph of the log likelihood for varying thetas
    #+RESULTS:
    [[file:figures/MLE_likelihood.png]]

    

*** Obtaining the MLE estimate 
    Although from the previous graph it's pretty obvious that the MLE
    estimate will be somewhere around 0.26, it would still be nice to
    formally know this. We start by finding the derivative: 

    \begin{equation}
    \frac{d L(X|p)}{d p} = k p^{k-1} (1-p)^{n-k} + p^k (n-k) (1-p)^{n-k-1} (-1)
    \end{equation}

    We can then set the derivative equal to zero and solve. 

    \begin{equation*}
    \begin{split}
    0 & =  k p^{k-1} (1-p)^{n-k} + p^k (n-k) (1-p)^{n-k-1} (-1) \\
    kp^{k-1} (1-p)^{n-k} & = p^k (n-k)(1-p)^{n-k-1} \\
    k(1-p) & = p(n-k) \\
    k-kp & = pn - pk \\
    p & = \frac{k}{n}
    \end{split}
    \end{equation*}

    So here $\hat{p}_{MLE} = \frac{k}{n} = {78}{261} \approx 0.299$


* MOM estimation
  Method of Moments estimation (MOM) is another way of getting
  estimators, just like MLE. It asks a slightly different question to
  get these estimators, though. Whereas MLE find the value of the
  parameter(s) that make your data the most likely to have occurred,
  MOM simply states that your sample "moments" are good estimators of
  the theoretical moments. 

  The general way to find the MOM estimators are to find the first $K$
  theoretical and sample moments, where $K$ represents the number of
  equations you have. You then set them equal to one another and solve
  for your estimators. 
** Find the theoretical moments
   The theoretical moments are simple. They're just $E(X^k)$ where $k$
   represents the theoretical moment. So if you want the first
   theoretical moment, that's just $E(X^1)$, or just $E(X)$. The second
   theoretical moment is just $E(X^2)$ and so on for higher-order
   moments. 
** Find the sample moments
   The sample moments are just as easy to find as the theoretical
   moments. The $k^{th}$ sample moment is just 
   
   \begin{equation}
   M_k = \dfrac{1}{n} \sum_{i=1}^n X_i^k
   \end{equation}

   Note that the first sample moment is $\dfrac{1}{n} \sum_{i=1}^{n} X_i$, which
   is simply $\bar{x}$
** Set these equal and solve 
** Example 1
   Let $x_1, x_2, ... x_n$ be random draws from a uniform distribution
   with an unknown lower bound but an upper bound of 100 (i.e. $x_i
   \sim U(a, 100)$)
   
   Then the pdf of this is: 

   \begin{equation}
   f(x) = \begin{cases} \frac{1}{100 - a} \quad a \leq x \leq 100 \\
          0 \qquad \text{ otherwise}
          \end{cases}
   \end{equation}

   Find the method of moments estimator for $a$. 
*** Theoretical moments
    We are estimating one parameter, so we only need to find the first
    theoretical moment. For a uniform, this is: 

    \begin{equation}
    E(X) = \int_a^b \frac{x}{100-a} dx = \frac{a + 100}{2}
    \end{equation}
*** Sample moments
    Again, we just need to find the first one, which is simply: 

    \begin{equation}
    \frac{1}{n} \sum_{i=1}^n x_i = \bar{x}
    \end{equation}

*** Solve for the estimator
    We set these equal and solve for the MOM estimator:

    \begin{equation*}
    \begin{split}
    \bar{x} & = \frac{a + 100}{2} \\
    2 \bar{x} & = a + 100 \\
    2 \bar{x} - 100 & = a
    \end{split}
    \end{equation*}

    So $a_{MOM} = 2 \bar{x} - 100$. 
    
** Example 2 
   Let $x_1, x_2, ... x_n$ be random draws from a uniform distribution
   (i.e. $X \sim U(a,b)$)
   and we need to calculate both of the bounds($a$ and $b$). Remember
   that the pdf of a uniform distribution is

   \begin{equation}
   f(x) = \begin{cases} \frac{1}{b - a} \quad a \leq x \leq b \\
          0 \qquad \text{ otherwise}
          \end{cases}
   \end{equation}

*** Theoretical moments
    Since we have two unknown parameters, we need to calculate the
    first two theoretical moments:

    \begin{equation}
    E(X) = \int_a^b \frac{x}{b-a} dx = \frac{a + b}{2}
    \end{equation}

    \begin{equation}
    E(X^2) = \int_a^b \frac{x^2}{b-a} dx = \frac{a^2 + ab + b^2}{3}
    \end{equation}

*** Sample moments
    We need to find the first two sample moments:

    \begin{equation}
    \frac{1}{n} \sum_{i=1}^n x_i = \bar{x}
    \end{equation}

    \begin{equation}
    \frac{1}{n} \sum_{i=1}^n x_i^2 = m_2
    \end{equation}

*** Set theoretical and sample moments equal and solve
    Now we just set the theoretical moments and sample moments equal
    to each other and solve to find our estimators. 
    \begin{equation}
    \bar{x} = \frac{a + b }{2} \qquad m_2 = \frac{a^2 + ab + b^2}{3}
    \end{equation}
    
    When we solve for $a$ and $b$, we get that (after some nasty
    algebra): 

    \begin{equation}
    \hat{a} = \bar{x} - \sqrt{3 \left( m_2 - \bar{x}^2 \right)} \qquad \hat{b} = \bar{x} + \sqrt{3 \left( m_2  - \bar{x}^2 \right)}
    \end{equation}
    

* Significance & Power 
  There are two kinds of errors we can make in hypothesis testing. A
  Type I error is committed when we reject $H_0$ when $H_0$ is actually
  true. We make a Type II error when we fail to reject a false
  null. Table [[tab-errors]] nicely summarizes this relationship. 

  #+NAME: tab-errors
  | $H_0$  | Decision |                |
  |       | Reject   | Fail to Reject |
  | True  | Type I   | $\checkmark$            |
  | False | $\checkmark$      | Type II        |
  
  There's an obvious tradeoff here between the frequency with which we
  commit either kind of error. In the limit, if we never reject a
  null, then we'll never commit a Type I error, but we'll never reject
  a false null either. We can formally define the probability of
  committing either kinds of error.

** Significance

  \begin{equation}
  \alpha = Pr( \text{Type I error} | H_0)
  \end{equation}
  
  Thus, $\alpha$ represents the probability of making a Type I error if the
  null is actually true. We use $\alpha$ such that there is $(1- \alpha)$
  probability of being inside the critical region is our null is
  true. If we see a test statistic outside that critical region, then
  we know there is a less than $\alpha$ percent chance that that would
  happen purely due to randomness if the null were actually true. This
  is the *significance* of a test. 

** Power

  \begin{equation}
  \beta = Pr(\text{Type II error})
  \end{equation}
  
  $\beta$, on the other hand, represents the probability of committing a
  Type II error. This is impossible to mathematically calculate most
  of the time, though. It's not enough just to say that the null isn't
  true - we need to specify what the true parameter is equal to in
  order to calculate $\beta$. We refer to $(1-\beta)$ as the *power* of a
  test. Usually, we'll look at how power varies as a function of
  unknown parameters or $n$. 

*** Example
    You've designed an experiment to test the effect of disgust on
    attitudes towards the incumbent. From the results of a pilot
    study, you believe that attitudes toward the incumbent are
    normally distributed with a mean of 50 and standard deviation
    of 6. You believe that your treatment will decrease the mean by 4
    points. How many participants do you need in order to detect this
    with 90 percent probability? Use a two-tailed test and $\alpha =
    0.05$. 

    Note here that $H_0: \mu =  50$ and $H_A: \mu \neq 50$. For this example,
    we'll assume that we know the standard deviation is $6$. Relaxing
    that assumption is pretty straightforward, though. So note that
    under the null, our estimator $\bar{x} \sim N(50, \frac{6^2}{n})$ and
    that if our guess about the effect size is true, then $\bar{x} \sim
    N(54, \frac{6^2}{n})$. 

    We can calculate the critical values as a function of $n$: 

    \begin{equation}
    50 \pm 1.96 \left( \sqrt{\frac{6^2}{n}} \right)
    \end{equation}

    So we'll reject if we see a value lower than that when we subtract
    or great than that when we add. Now we just need to figure out the
    probability of that happening if the true effect is to lower the
    mean by 6 points. That's pretty easy to do - we know that if we
    subtract off the mean and divide by the standard deviation, then
    we've standardized our variable and can look up probabilities
    using the standard normal table. So to find the probability of
    being /less/ than the critical value, we:

    #+NAME: eq-less
    \begin{equation}
    \Phi\left( \frac{ \left( 50 - 1.96 \left( \sqrt{\frac{6^2}{n}} \right) \right) - 54}{\sqrt{\frac{6^2}{n}}}\right)
    \end{equation}

    And then we add that to the probability of being /greater/ than
    our other critical value:

    #+NAME: eq-greater
    \begin{equation}
    1 - \Phi\left( \frac{ \left( 50 + 1.96 \left( \sqrt{\frac{6^2}{n}} \right) \right) - 54}{\sqrt{\frac{6^2}{n}}}\right) 
    \end{equation}

    So Equation [[eq-less]] plus Equation [[eq-greater]] gives us the
    probability of rejecting the null hypothesis if the true mean is
    actually 54 instead of 50. 

    Now we can actually answer the question that we're interested
    in. We want to know the number of participants needed in order to
    detect this effect with a probability of 0.90. 

    #+BEGIN_SRC R :results output graphics :file figures/power-test.png :width 400 :height 300 :exports both
      our_power_test <- function(n){
        left <- pnorm(((50 - 1.96 * sqrt(6 ^ 2 / n)) - 54) / sqrt(6 ^ 2 / n))
        right <- 1 - pnorm(((50 + 1.96 * sqrt(6 ^ 2 / n)) - 54) / sqrt(6 ^ 2 / n))
        left + right
      }

      library(ggplot2)

      ggplot(data.frame(n=c(0, 100)), aes(n)) +
        stat_function(fun = our_power_test) +
        geom_hline(yintercept = .9, linetype = "dashed")
    #+END_SRC

    #+NAME: fig-power
    #+CAPTION: Power tests
    #+RESULTS:
    [[file:figures/power-test.png]]
    
    So from Figure [[fig-power]], we can see that we'd need about 25
    people in order to detect this with 90 percent probability. 
